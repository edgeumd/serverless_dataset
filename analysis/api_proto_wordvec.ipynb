{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import remove_empty_base as rm\n",
    "import os\n",
    "import glob\n",
    "from itertools import chain\n",
    "\n",
    "def get_code_files(repo_path, language=\"js\", language_oblivious=False):\n",
    "    \"\"\"\n",
    "    Get code files from a repository\n",
    "    :param repo_path:\n",
    "    :param language:\n",
    "    \"\"\"\n",
    "    if(language_oblivious):\n",
    "        languages = [\"js\", \"py\", \"java\", \"c\", \"cpp\", \"cs\", \"go\",\"ts\"]\n",
    "        files = []\n",
    "        for language in languages:\n",
    "            files.extend(rm.find_files(repo_path, \"*.{}\".format(language), depth=7))\n",
    "        return files\n",
    "\n",
    "    files = rm.find_files(repo_path, \"*.{}\".format(language), depth=7)\n",
    "    return files\n",
    "\n",
    "\n",
    "def get_name(repo_path, from_end=1):\n",
    "    \"\"\"\n",
    "    Get repo name given the repo path.\n",
    "    :param repo_path:\n",
    "    \"\"\"\n",
    "    return repo_path.split(\"/\")[-from_end]\n",
    "\n",
    "\n",
    "\n",
    "def get_code_name(code_path):\n",
    "    \"\"\"\n",
    "    Get name of code file\n",
    "    \"\"\"\n",
    "    return \"\".join(code_path.split(\"/\")[-1].split(\".\")[0:-1])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "platform = \"azure\"\n",
    "from code_handler import CodePreprocessor as cp\n",
    "z = cp([\"sss\"])\n",
    "base_path = \"./storage/nfs/\" + platform + \"/\"\n",
    "import glob\n",
    "import os\n",
    "\n",
    "repositories = glob.glob(os.path.join(base_path, \"*\",\"*\"))\n",
    "configs = {\n",
    "    \"serverless\": \"serverless.yml\",\n",
    "    \"azure\": \"function.json\",\n",
    "    \"aws\": \"template.yml\",\n",
    "    \"ibm\": \"manifest.yml\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# API FREQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import remove_empty_base as rm\n",
    "import os\n",
    "import glob\n",
    "from itertools import chain\n",
    "import api_nodes\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import networkx as nx\n",
    "import os\n",
    "import glob\n",
    "from itertools import chain\n",
    "import toydataset as td\n",
    "\n",
    "def read_api(platform=\"serverless\"):\n",
    "    with open(\"storage/oneplace/{}_api_dict.json\".format(platform), \"r\") as fp:\n",
    "        api_dict = json.load(fp)\n",
    "    return api_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_api_counts(api_dict):\n",
    "    \"\"\"\n",
    "    Given an api_dict, returns a dictionary of api counts\n",
    "\n",
    "    :params:\n",
    "        api_dict: dictionary of repository: api_string_list (\"api1 api2 api3\")\n",
    "    :returns:\n",
    "        api_counts: dictionary of api:count\n",
    "    \n",
    "    \"\"\"\n",
    "    from collections import Counter\n",
    "    api_counts = Counter()\n",
    "    for i in api_dict:\n",
    "        res = api_dict[i].split(\" \")\n",
    "        for api in res:\n",
    "            if(api == \"\"):\n",
    "                continue\n",
    "            api_counts[api] += 1\n",
    "    return api_counts\n",
    "\n",
    "\n",
    "def get_weight(api, api_counts, adjust_by=10, clip=None):\n",
    "    \"\"\"\n",
    "    Given an api and api_counts, returns the weight of the api\n",
    "\n",
    "    :params:\n",
    "        api: api to be weighted\n",
    "        api_counts: api_counts dictionary\n",
    "        adjust_by: adjust the weight by this value\n",
    "        clip: clip the weight to this value\n",
    "    :returns:\n",
    "        weight: weight of the api\n",
    "\n",
    "    \"\"\"\n",
    "    res = api_counts[api]\n",
    "    if(clip != None and res < clip):\n",
    "        return 0\n",
    "    if(res != 0):\n",
    "        return (1/res) * adjust_by\n",
    "        # return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_code_files(repo_path, language=\"js\", language_oblivious=False):\n",
    "    \"\"\"\n",
    "    Get code files from a repository\n",
    "    :param repo_path:\n",
    "    :param language:\n",
    "    \"\"\"\n",
    "    if(language_oblivious):\n",
    "        languages = [\"js\", \"py\", \"java\", \"c\", \"cpp\", \"cs\", \"go\",\"ts\"]\n",
    "        files = []\n",
    "        for language in languages:\n",
    "            files.extend(rm.find_files(repo_path, \"*.{}\".format(language), depth=7))\n",
    "        return files\n",
    "\n",
    "    files = rm.find_files(repo_path, \"*.{}\".format(language), depth=7)\n",
    "    return files\n",
    "\n",
    "\n",
    "def get_name(repo_path, from_end=1):\n",
    "    \"\"\"\n",
    "    Get repo name given the repo path.\n",
    "    :param repo_path:\n",
    "    \"\"\"\n",
    "    return repo_path.split(\"/\")[-from_end]\n",
    "\n",
    "\n",
    "\n",
    "def get_code_name(code_path):\n",
    "    \"\"\"\n",
    "    Get name of code file\n",
    "    \"\"\"\n",
    "    return \"\".join(code_path.split(\"/\")[-1].split(\".\")[0:-1])\n",
    "\n",
    "\n",
    "\n",
    "def get_api_dict(platform, repositories):\n",
    "    \"\"\"\n",
    "    Returns api_dict i.e. a dictionary of repo_name: all_apis\n",
    "\n",
    "    :params:\n",
    "        platform: str - platform name e.g. serverless, azure, aws, ibm\n",
    "        repositories: list of repositories [name1, name2, ...]\n",
    "\n",
    "    :return:\n",
    "        api_dict: dict - {repo_name: all_apis}\n",
    "    \"\"\"\n",
    "    from code_handler import CodePreprocessor as cp\n",
    "    z = cp([\"sss\"])\n",
    "    import api_nodes\n",
    "    location_mapping = api_nodes.repo_location_mapping()\n",
    "    api_dict = dict()\n",
    "    store_path = './storage/oneplace/{}/apis/'.format(platform)\n",
    "    repositories_loc = [location_mapping[repo][0] for repo in repositories if repo in location_mapping]\n",
    "    for repo in repositories_loc:\n",
    "        # print(repo)\n",
    "        # break\n",
    "        code_files = get_code_files(repo, language_oblivious=True)[:1]\n",
    "        # print(code_files)\n",
    "        # break\n",
    "        repo_name = get_name(repo)\n",
    "        all_apis = []\n",
    "        # TODO procedure for javascript files and typescript files\n",
    "        # if(len(code_files) > 0 and (z.code_lang(code_files[0]) == \"js\" or z.code_lang(code_files[0]) == \"ts\")):\n",
    "        #     # TODO find package.json\n",
    "        #     # TODO parse package.json\n",
    "        #     # TODO find all dependencies\n",
    "        #     pass\n",
    "        # else:    \n",
    "        for i in code_files:\n",
    "            try:\n",
    "                name = get_code_name(i)\n",
    "                # print(name)\n",
    "                language = z.code_lang(path=i)\n",
    "                # language = i.split(\".\")[-1]\n",
    "                # print(language)\n",
    "                code = z.load_raw_code(i)\n",
    "                # print(code)\n",
    "                # break\n",
    "                apis = z.get_imports(language,code)\n",
    "                all_apis.append(apis)\n",
    "                # print(all_apis)\n",
    "                # break\n",
    "            except:\n",
    "                # print(\"ERROR : {}\".format(i))\n",
    "                continue\n",
    "        \n",
    "        # print(all_apis)\n",
    "        all_apis = list(chain.from_iterable(all_apis))\n",
    "        # print(all_apis)\n",
    "        all_apis = (set(all_apis))\n",
    "        if \"\" in all_apis:\n",
    "            all_apis.remove(\"\")\n",
    "        all_apis = \" \".join(all_apis)\n",
    "        # print(all_apis)\n",
    "        # break\n",
    "        if(repo_name not in api_dict):\n",
    "            api_dict[repo_name] = all_apis\n",
    "        # if(not os.path.exists(store_path + repo_name + \"/\")):\n",
    "        #     os.makedirs(store_path + repo_name + \"/\")\n",
    "\n",
    "    return api_dict\n",
    "\n",
    "def get_api_dict_for(repository, location_mapping):\n",
    "    \"\"\"\n",
    "    Returns api dict for repo name.\n",
    "    :params:\n",
    "        repository: repository name\n",
    "        location_mapping: location mapping\n",
    "\n",
    "    :returns:\n",
    "        api_dict: api dict for the repo (can be used for multi repo search)\n",
    "    \"\"\"\n",
    "    repo_platform = location_mapping[repository]\n",
    "    return get_api_dict(repo_platform, [repository])\n",
    "\n",
    "\n",
    "def get_api_dict_for_repositories(repositories, location_mapping):\n",
    "    \"\"\"\n",
    "    Returns api dict for repositories of multiple platform.\n",
    "\n",
    "    :params:\n",
    "        repositories: repositories belonging to different platforms.\n",
    "        location_mapping: location mapping\n",
    "\n",
    "    :returns:\n",
    "        api_dict: api dict for the repo (can be used for multi repo search)\n",
    "    \"\"\"\n",
    "    api_dict = dict()\n",
    "    for repo in repositories:\n",
    "        if repo not in location_mapping:\n",
    "            continue\n",
    "        repo_platform = location_mapping[repo]\n",
    "        api_dict.update(get_api_dict(repo_platform, [repo]))\n",
    "    return api_dict\n",
    "\n",
    "\n",
    "def get_repo_weight_dict(repo_list_with_weights):\n",
    "    \"\"\"\n",
    "    Returns repository:weight dictionary from search with score = true.\n",
    "\n",
    "    :params:\n",
    "        repo_list_with_weights: result of api_nodes.search_repositories ([[0,0,0,0,0,reponame]])\n",
    "\n",
    "    :returns:\n",
    "        repo_weight_dict: dictionary of repo:weight\n",
    "\n",
    "    \"\"\"\n",
    "    repo_weight_dict = {}\n",
    "    for i in repo_list_with_weights:\n",
    "        repo_weight_dict[i[-1]] = i[0]\n",
    "    return repo_weight_dict\n",
    "\n",
    "\n",
    "def calc_weight_between_repositories(repo1, repo2, counts):\n",
    "    \"\"\"\n",
    "    Given two repositories, returns the weight of the edge between them\n",
    "\n",
    "    :params:\n",
    "        repo1: repository name\n",
    "        repo2: repository name\n",
    "        counts: api_counts dictionary\n",
    "    :returns:\n",
    "        weight: weight of the edge between the two repositories\n",
    "\n",
    "    \"\"\"\n",
    "    # Base case.\n",
    "    if(repo1 == repo2):\n",
    "        return 0\n",
    "\n",
    "    average = int(sum(list(counts.values()))/len(list(counts.values())))\n",
    "    \n",
    "    corressponding = {\n",
    "        \"s3\": \"blob\",\n",
    "        \"S3\": \"blob\",\n",
    "        \"dynamodb\": \"cosmos\",\n",
    "        \"DynamoDB\": \"cosmos\",\n",
    "        \"sns\":\"eventgrid\",\n",
    "        \"sns\":\"event-grid\",\n",
    "        \"sqs\":\"queue\",\n",
    "        \"ses\":\"sendgrid\",\n",
    "        \"kinesis\":\"eventhub\",\n",
    "        \"kinesis\":\"event-hubs\",\n",
    "        \"kinesisanalytics\":\"eventhub\",\n",
    "        \"kinesisanalytics\":\"event-hubs\",\n",
    "        \"lex\":\"botbuilder\",\n",
    "        \"polly\":\"speech\",\n",
    "    }\n",
    "    corressponding_rev = {v:k for k,v in corressponding.items()}\n",
    "    corressponding.update(corressponding_rev)\n",
    "\n",
    "    # If both repositories is known then proceed.\n",
    "    if(repo1 in api_dict and repo2 in api_dict):\n",
    "        api_list1 = api_dict[repo1].split(\" \")\n",
    "        tmp = [corressponding[i] for i in api_list1 if i in corressponding]\n",
    "        api_list1.extend(tmp)\n",
    "        api_list2 = api_dict[repo2].split(\" \")\n",
    "        # First Set, add corressponding apis.\n",
    "        common_apis = set(api_list1).intersection(api_list2)\n",
    "        if(len(common_apis) == 0):\n",
    "            return 0\n",
    "        return sum([get_weight(i, counts, clip=average) for i in common_apis])\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "\n",
    "def get_community_energy(community, repo_weight):\n",
    "    \"\"\"\n",
    "    Given a community and repo_weight dictionary, returns the energy of the community\n",
    "\n",
    "    :params:\n",
    "        community: community to be evaluated\n",
    "        repo_weight: dictionary of repo:weight\n",
    "    :returns:\n",
    "        energy: energy of the community\n",
    "\n",
    "    \"\"\"\n",
    "    if(len(community) < 3):\n",
    "        return 0\n",
    "    return sum([repo_weight[i] for i in community])/len(community)\n",
    "\n",
    "\n",
    "def find_match(selected_apis,repositories, api_dict, threshold=1,skip=False):\n",
    "    \"\"\"\n",
    "    Given a repository and api_dict, returns the number of matching apis.\n",
    "\n",
    "    :params:\n",
    "        selected_apis: set of selected apis\n",
    "        repository: repository name\n",
    "        api_dict: api_dict dictionary\n",
    "        threshold: threshold for matching\n",
    "    :returns:\n",
    "        match: number of matching apis\n",
    "\n",
    "    \"\"\"\n",
    "    res = []\n",
    "    for repository in repositories:\n",
    "        if(repository in api_dict):\n",
    "            api_list = api_dict[repository].split(\" \")\n",
    "            if(skip):\n",
    "                if(len(api_list) > 15):\n",
    "                    continue\n",
    "            mlen = len([i for i in api_list if i in selected_apis])\n",
    "            if(mlen > threshold):\n",
    "                res.append(repository)\n",
    "    return res\n",
    "\n",
    "def get_license(repo, location_mapping, license_specific:rm.LicenseSpecific):\n",
    "    \"\"\"\n",
    "    Given location mapping and repository name, find the license of the repository.\n",
    "\n",
    "    :params:\n",
    "        repo: repository name\n",
    "        location_mapping: location mapping dictionary\n",
    "        license_specific: license specific object from remove_empty_sarvesh\n",
    "\n",
    "    :returns:\n",
    "        license: license of the repository\n",
    "    \"\"\"\n",
    "    # Get platform\n",
    "    platform = location_mapping[repo][1]\n",
    "\n",
    "    # Build query\n",
    "    query = \"storage/oneplace/{}/apis/{}/License\".format(platform,repo)\n",
    "\n",
    "    # Check if exists.\n",
    "    if(not os.path.exists(query)):\n",
    "        return \"NONE\"\n",
    "\n",
    "    # Get license\n",
    "    license = license_specific.which_license(query)\n",
    "\n",
    "    return license"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# api_dict = read_api(platform=\"serverless\")\n",
    "# api_dict.update(read_api(platform=\"aws\"))\n",
    "# api_dict.update(read_api(platform=\"azure\"))\n",
    "# api_dict.update(read_api(platform=\"ibm\"))\n",
    "# api_dict = get_api_dict_for_repositories(ntmp, location_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# counts = get_api_counts(api_dict)\n",
    "location_mapping = api_nodes.repo_location_mapping()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"slack bot to send message to slack\"\n",
    "ffrepos = td.get_repositories()\n",
    "tmp = api_nodes.search_repositories_for(query, ffrepos, location_mapping, num=10, with_score=True, all_repos=True, thres=50,word_vec=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "searched_repositories = tmp.copy()\n",
    "ntmp = [i[-1] for i in tmp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "\n",
    "import glob\n",
    "allrepos = [i.split(\"/\")[-1] for i in glob.glob(\"storage/oneplace/*/*/*\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_dict = get_api_dict_for_repositories(allrepos, location_mapping)\n",
    "import pickle\n",
    "with open(\"api_dict.pkl\", \"wb\") as f:\n",
    "    pickle.dump(api_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "def load_api_dict(path=\"api_dict.pkl\"):\n",
    "    \"\"\"\n",
    "    Load's the api_dict.pkl file.\n",
    "\n",
    "    :params:\n",
    "        path: path to the api_dict.pkl file\n",
    "    \n",
    "    :returns:\n",
    "        global_api_dict: global_api_dict dictionary\n",
    "    \"\"\"\n",
    "    with open(path, \"rb\") as f:\n",
    "        return pickle.load(f)\n",
    "\n",
    "\n",
    "def get_api_dict_from_global(ntmp, global_api_dict):\n",
    "    \"\"\"\n",
    "    Given a list of repositories, returns a dictionary of api_dict for the repositories.\n",
    "\n",
    "    :params:\n",
    "        ntmp: list of repositories\n",
    "        global_api_dict: global api_dict dictionary\n",
    "\n",
    "    :returns:\n",
    "        api_dict: api_dict dictionary\n",
    "    \"\"\"\n",
    "    api_dict = {}\n",
    "    for repo in ntmp:\n",
    "        if(repo in global_api_dict):\n",
    "            api_dict[repo] = global_api_dict[repo]\n",
    "    return api_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_api_dict = load_api_dict()\n",
    "api_dict = get_api_dict_from_global(ntmp, global_api_dict)\n",
    "counts = get_api_counts(api_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "repo_weight = get_repo_weight_dict(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.Graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "G.add_nodes_from(list(repo_weight.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making the graph starts here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "repositories = list(repo_weight.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_weight_between_repositories(repositories[0], repositories[5], counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(repositories)):\n",
    "    for j in range(i+1, len(repositories)):\n",
    "        # calculate weight between two repos needed.\n",
    "        w = calc_weight_between_repositories(repositories[i], repositories[j], counts)\n",
    "        if(w != 0):\n",
    "            G.add_edge(repositories[i], repositories[j], weight=w)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find communities based on the weights.\n",
    "from networkx.algorithms.community import louvain_communities\n",
    "partition = louvain_communities(G, weight='weight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now partition has communities.\n",
    "# We need a function to determine energy of the community.\n",
    "# Energy is defined as the sum of repo weight in community divided by the number of repository in a community?\n",
    "# It will basically indicate average repository energy.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_comm = set()\n",
    "max_energy = 0\n",
    "for i in partition:\n",
    "    energy = get_community_energy(i, repo_weight)\n",
    "    if(energy > max_energy):\n",
    "        max_energy = energy\n",
    "        max_comm = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.266862876761951"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "fin = []\n",
    "for res in max_comm:\n",
    "    fin.append((res, repo_weight[res]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_comm = [i[0] for i in sorted(fin, key=lambda x: x[1], reverse=True)[:30]] # I want most common api of top 30 strongest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next todo is to get the most frequent api's in the community."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlis = []\n",
    "for i in new_comm:\n",
    "    tmp = api_dict[i]\n",
    "    tmp = tmp.split(\" \")\n",
    "    mlis.extend(tmp)\n",
    "\n",
    "mlis = Counter(mlis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_apis = {i[0] for i in mlis.most_common(15)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ntmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bscaspar_serverless-cognito-auth',\n",
       " 'darwaishx_rekognition-sqs',\n",
       " 'enr1c091_amazon-cognito-facial-recognition-auth',\n",
       " 'HaifengMei_go-ceries-server',\n",
       " 'Sai503_GdriveImagetoPDF',\n",
       " 'angelo-munoz_image-to-text',\n",
       " 'preshetin_csv-to-dynamodb',\n",
       " 'ioviic_RecordMe',\n",
       " 'davidpallmann_world-factbook-site']"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_comm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Decimal',\n",
       " 'DynamoDB',\n",
       " 'TestCase',\n",
       " 'botocore.vendored',\n",
       " 'csv-parser',\n",
       " 'decimal',\n",
       " 'dynamodb',\n",
       " 'fetch',\n",
       " 'googleapis',\n",
       " 'node-fetch',\n",
       " 'pytest',\n",
       " 's3',\n",
       " 'ses',\n",
       " 'unittest',\n",
       " 'webpack-node-externals'}"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_apis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter results based on the selected apis.\n",
    "query = \"slack bot to send message to slack\"\n",
    "tmp = api_nodes.search_repositories_for(query,ffrepos,location_mapping, num=20,with_score=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SiarheiMelnik_gather-bot',\n",
       " 'ConsenSysMesh_Luxarity-SensuiMod',\n",
       " 'AlexeyPerov_LogKeeper-Flutter-Firebase',\n",
       " 'miridius_serverless-telegram',\n",
       " 'revmischa_qanda',\n",
       " 'keetonian_cw-logs-to-chime',\n",
       " 'jayfry1077_serverless_discord_diceroll_bot',\n",
       " 'JuHwon_lambda-log-shipper',\n",
       " 'kdcio_serverless-html-to-pdf',\n",
       " 'amuelli_serverless-slack-lunch-hunter',\n",
       " 'sturman_bus_lviv_bot',\n",
       " 'AnilRedshift_captions_please',\n",
       " 'harshkavdikar1_s3-to-gcs-streaming',\n",
       " 'david--wright_habiticabot',\n",
       " 'stuartleaver_discord-reminders-azure-functions',\n",
       " 'cossou_mws-orders-webhook',\n",
       " 'jayfry1077_serverless_discord_LFG_bot',\n",
       " 'sam-negotiator_website-change-monitor',\n",
       " 'angelo-munoz_image-to-text',\n",
       " 'marteinn_Cynomys']"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['revmischa_qanda', 'jayfry1077_serverless_discord_LFG_bot', 'sam-negotiator_website-change-monitor', 'angelo-munoz_image-to-text']\n"
     ]
    }
   ],
   "source": [
    "selected_low = find_match(selected_apis,tmp,api_dict,threshold=1)\n",
    "print(selected_low)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SiarheiMelnik_gather-bot',\n",
       " 'ConsenSysMesh_Luxarity-SensuiMod',\n",
       " 'AlexeyPerov_LogKeeper-Flutter-Firebase',\n",
       " 'miridius_serverless-telegram',\n",
       " 'revmischa_qanda',\n",
       " 'keetonian_cw-logs-to-chime',\n",
       " 'jayfry1077_serverless_discord_diceroll_bot',\n",
       " 'JuHwon_lambda-log-shipper',\n",
       " 'kdcio_serverless-html-to-pdf',\n",
       " 'amuelli_serverless-slack-lunch-hunter',\n",
       " 'sturman_bus_lviv_bot',\n",
       " 'AnilRedshift_captions_please',\n",
       " 'harshkavdikar1_s3-to-gcs-streaming',\n",
       " 'david--wright_habiticabot',\n",
       " 'stuartleaver_discord-reminders-azure-functions',\n",
       " 'cossou_mws-orders-webhook',\n",
       " 'jayfry1077_serverless_discord_LFG_bot',\n",
       " 'sam-negotiator_website-change-monitor',\n",
       " 'angelo-munoz_image-to-text',\n",
       " 'marteinn_Cynomys']"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'loghelpers gzip lambdainit test extract lambdalogging chime patch config handlers base pytest'"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "api_dict[\"keetonian_cw-logs-to-chime\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Decimal',\n",
       " 'DynamoDB',\n",
       " 'TestCase',\n",
       " 'botocore.vendored',\n",
       " 'csv-parser',\n",
       " 'decimal',\n",
       " 'dynamodb',\n",
       " 'fetch',\n",
       " 'googleapis',\n",
       " 'node-fetch',\n",
       " 'pytest',\n",
       " 's3',\n",
       " 'ses',\n",
       " 'unittest',\n",
       " 'webpack-node-externals'}"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_apis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# global_api_dict = read_api(platform=\"serverless\")\n",
    "# global_api_dict.update(read_api(platform=\"aws\"))\n",
    "# global_api_dict.update(read_api(platform=\"azure\"))\n",
    "# global_api_dict.update(read_api(platform=\"ibm\"))\n",
    "# global_api_dict = get_api_dict_for_repositories(ffrepos, location_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['yomageli_yogeo', 'angelo-munoz_image-to-text', 'enr1c091_amazon-cognito-facial-recognition-auth']\n"
     ]
    }
   ],
   "source": [
    "selected_high = find_match(selected_apis,list(global_api_dict.keys()),global_api_dict,threshold=6,skip=True)\n",
    "print(selected_high)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'checkpoint dynamodb lambdainit ClientError botocore.exceptions unittest.mock test MagicMock Attr twitter poller ses pytest'"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "global_api_dict[\"awslabs_aws-serverless-twitter-event-source\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "location_mapping = api_nodes.repo_location_mapping()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['storage/nfs/aws/13001-13201/awslabs_aws-serverless-twitter-event-source',\n",
       " 'aws']"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "location_mapping[\"awslabs_aws-serverless-twitter-event-source\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls = rm.LicenseSpecific()\n",
    "final_selected = set(selected_low + selected_high)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enr1c091_amazon-cognito-facial-recognition-auth   ('mit', 0.9831618334892422)\n",
      "jayfry1077_serverless_discord_LFG_bot   ('mit', 0.9817842129845866)\n",
      "revmischa_qanda   ('lgpl3', 0.019661911041841507)\n",
      "yomageli_yogeo   ('mit', 0.8598598598598599)\n",
      "angelo-munoz_image-to-text   ('mit', 0.9840823970037453)\n",
      "sam-negotiator_website-change-monitor   ('mit', 0.9854664791373652)\n"
     ]
    }
   ],
   "source": [
    "for i in final_selected:\n",
    "    print(i, \" \", get_license(i, location_mapping, ls))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global api dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "tot = 0\n",
    "count = 0\n",
    "for repo in api_dict:\n",
    "    res = api_dict[repo].split(\" \")\n",
    "    tot += len(res)\n",
    "    count += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.7985566363351113"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tot/count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
